{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3428,"databundleVersionId":31210,"sourceType":"competition"}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"In this notebook, the power of SKlearn library is explored through a sample data in a binary classification setting. The analysis considers the following setps:\n1. Data Pre Processing/data description\n2. Dimensional Analysis\n3. Applying non-parametric learniong method - KNN, Tree based models\n4. Classification with NaiveBayes with assumptions about data\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split,GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import neighbors\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.naive_bayes import ComplementNB,MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\nimport seaborn as sns\nsns.set(style=\"ticks\", color_codes=True)\nfrom sklearn.feature_selection import RFECV","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:24:59.972644Z","iopub.execute_input":"2023-11-14T19:24:59.973915Z","iopub.status.idle":"2023-11-14T19:25:00.023738Z","shell.execute_reply.started":"2023-11-14T19:24:59.973873Z","shell.execute_reply":"2023-11-14T19:25:00.022184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import  matplotlib.pyplot as plt\nimport seaborn as sn\nfrom sklearn.decomposition import PCA\nimport scipy.stats as stats\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\nimport numpy as np\nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:19:32.980933Z","iopub.execute_input":"2023-11-14T19:19:32.981421Z","iopub.status.idle":"2023-11-14T19:19:32.991173Z","shell.execute_reply.started":"2023-11-14T19:19:32.981385Z","shell.execute_reply":"2023-11-14T19:19:32.990226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dirname\nfilenames","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:19:34.795744Z","iopub.execute_input":"2023-11-14T19:19:34.796617Z","iopub.status.idle":"2023-11-14T19:19:34.802841Z","shell.execute_reply.started":"2023-11-14T19:19:34.796580Z","shell.execute_reply":"2023-11-14T19:19:34.801964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Pre-Processing","metadata":{}},{"cell_type":"code","source":"train_df=pd.read_csv(os.path.join(dirname, filenames[1]))\ntrain_df.columns\ntrain_labels=pd.read_csv(os.path.join(dirname, filenames[0]))\nprint(train_labels.head(3))\ntest_df=pd.read_csv(os.path.join(dirname, filenames[2]))\nprint(test_df.head(3))","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:19:36.730690Z","iopub.execute_input":"2023-11-14T19:19:36.731456Z","iopub.status.idle":"2023-11-14T19:19:36.918651Z","shell.execute_reply.started":"2023-11-14T19:19:36.731421Z","shell.execute_reply":"2023-11-14T19:19:36.917618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"test_df.index\nmy_submission = pd.DataFrame({'id':test_df.index,'Solution':[x for x in range(0,9000)]})\nmy_submission","metadata":{"execution":{"iopub.status.busy":"2023-11-14T18:47:04.990316Z","iopub.execute_input":"2023-11-14T18:47:04.991619Z","iopub.status.idle":"2023-11-14T18:47:05.904666Z","shell.execute_reply.started":"2023-11-14T18:47:04.991562Z","shell.execute_reply":"2023-11-14T18:47:05.902259Z"}}},{"cell_type":"code","source":"#Assigning the column header as the first row for train and the test datasets\ntrain_df=pd.concat([train_df.columns.to_frame().T, train_df],ignore_index=True)\nprint(train_df.shape)\ntest_df=pd.concat([test_df.columns.to_frame().T, test_df],ignore_index=True)\nprint(test_df.shape)\ntrain_labels=pd.concat([train_labels.columns.to_frame().T, train_labels],ignore_index=True)\nprint(train_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:19:39.268272Z","iopub.execute_input":"2023-11-14T19:19:39.269257Z","iopub.status.idle":"2023-11-14T19:19:39.302722Z","shell.execute_reply.started":"2023-11-14T19:19:39.269198Z","shell.execute_reply":"2023-11-14T19:19:39.301329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"whole_data=pd.concat([train_df,test_df],ignore_index=True)\nwhole_data","metadata":{"execution":{"iopub.status.busy":"2023-11-14T20:28:59.988825Z","iopub.execute_input":"2023-11-14T20:28:59.989322Z","iopub.status.idle":"2023-11-14T20:29:00.031404Z","shell.execute_reply.started":"2023-11-14T20:28:59.989278Z","shell.execute_reply":"2023-11-14T20:29:00.030542Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels=train_labels.astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:19:42.307974Z","iopub.execute_input":"2023-11-14T19:19:42.308433Z","iopub.status.idle":"2023-11-14T19:19:42.315038Z","shell.execute_reply.started":"2023-11-14T19:19:42.308398Z","shell.execute_reply":"2023-11-14T19:19:42.313782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:19:43.220067Z","iopub.execute_input":"2023-11-14T19:19:43.220822Z","iopub.status.idle":"2023-11-14T19:19:43.229508Z","shell.execute_reply.started":"2023-11-14T19:19:43.220784Z","shell.execute_reply":"2023-11-14T19:19:43.228640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Changing the column names of the dataframe for train and the test dataframe\ncol=[]\nfor i in range(train_df.shape[1]):\n    col.append(f'f_{i}')\ntrain_df.columns=col\ntest_df.columns=col\ntrain_labels.columns=['label']","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:19:45.172711Z","iopub.execute_input":"2023-11-14T19:19:45.173171Z","iopub.status.idle":"2023-11-14T19:19:45.181209Z","shell.execute_reply.started":"2023-11-14T19:19:45.173140Z","shell.execute_reply":"2023-11-14T19:19:45.179342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.columns","metadata":{"execution":{"iopub.status.busy":"2023-11-14T18:52:58.101940Z","iopub.execute_input":"2023-11-14T18:52:58.102491Z","iopub.status.idle":"2023-11-14T18:52:58.114048Z","shell.execute_reply.started":"2023-11-14T18:52:58.102451Z","shell.execute_reply":"2023-11-14T18:52:58.112442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.dtypes\ntrain_df=train_df.astype(float)\ntest_df=test_df.astype(float)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:19:47.627365Z","iopub.execute_input":"2023-11-14T19:19:47.628825Z","iopub.status.idle":"2023-11-14T19:19:47.671943Z","shell.execute_reply.started":"2023-11-14T19:19:47.628763Z","shell.execute_reply":"2023-11-14T19:19:47.671010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Checking for missing values\ntrain_df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:19:49.890539Z","iopub.execute_input":"2023-11-14T19:19:49.891041Z","iopub.status.idle":"2023-11-14T19:19:49.904076Z","shell.execute_reply.started":"2023-11-14T19:19:49.891006Z","shell.execute_reply":"2023-11-14T19:19:49.902654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"Variance measures the spread or dispersion of data points in a dataset. It quantifies how much individual data points deviate from the mean (average) of the dataset. A high variance indicates that data points are more spread out, while a low variance suggests that data points are closer to the mean.\n","metadata":{}},{"cell_type":"code","source":"print(train_df.var())\nprint(train_df.skew())","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:19:52.036065Z","iopub.execute_input":"2023-11-14T19:19:52.037187Z","iopub.status.idle":"2023-11-14T19:19:52.053334Z","shell.execute_reply.started":"2023-11-14T19:19:52.037130Z","shell.execute_reply":"2023-11-14T19:19:52.051392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualising with boxplots\n","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,6))\ntrain_df.boxplot()\nplt.title('Boxplot of Variables')\nplt.ylabel('Value')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:19:54.262953Z","iopub.execute_input":"2023-11-14T19:19:54.263382Z","iopub.status.idle":"2023-11-14T19:19:55.184153Z","shell.execute_reply.started":"2023-11-14T19:19:54.263350Z","shell.execute_reply":"2023-11-14T19:19:55.182825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"f_4,f_12,f_23 features have high number of outliers.","metadata":{}},{"cell_type":"code","source":"train_labels","metadata":{"execution":{"iopub.status.busy":"2023-11-14T18:53:12.119785Z","iopub.execute_input":"2023-11-14T18:53:12.120283Z","iopub.status.idle":"2023-11-14T18:53:12.138171Z","shell.execute_reply.started":"2023-11-14T18:53:12.120245Z","shell.execute_reply":"2023-11-14T18:53:12.136249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_1=pd.concat([train_df, train_labels],axis=1)\ntrain_df_1","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:22:21.808522Z","iopub.execute_input":"2023-11-14T19:22:21.809029Z","iopub.status.idle":"2023-11-14T19:22:21.849733Z","shell.execute_reply.started":"2023-11-14T19:22:21.808991Z","shell.execute_reply":"2023-11-14T19:22:21.848392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.hist(figsize=(20,10))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:22:22.957553Z","iopub.execute_input":"2023-11-14T19:22:22.958733Z","iopub.status.idle":"2023-11-14T19:22:29.931569Z","shell.execute_reply.started":"2023-11-14T19:22:22.958608Z","shell.execute_reply":"2023-11-14T19:22:29.930160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlation_matrix=pd.DataFrame(train_df.corr()) #Taking the correlartion between dependent variables\n\ncorrelation_matrix.reset_index(level=0, inplace=True)\ncorrelation_matrix.head()\n#Converting the data from wide to long format\ncorrelation_matrix=pd.melt(correlation_matrix, id_vars=['index'], var_name='Variable', value_name='corr')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:22:29.933966Z","iopub.execute_input":"2023-11-14T19:22:29.934745Z","iopub.status.idle":"2023-11-14T19:22:29.955873Z","shell.execute_reply.started":"2023-11-14T19:22:29.934711Z","shell.execute_reply":"2023-11-14T19:22:29.954228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlation_matrix[(correlation_matrix['corr'].abs() > 0.5) & (correlation_matrix['corr'] < 1)]","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:22:29.957400Z","iopub.execute_input":"2023-11-14T19:22:29.958571Z","iopub.status.idle":"2023-11-14T19:22:29.975889Z","shell.execute_reply.started":"2023-11-14T19:22:29.958529Z","shell.execute_reply":"2023-11-14T19:22:29.974208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,axes=plt.subplots(1,3,figsize=(10,5))\naxes[0].scatter(train_df['f_28'],train_df['f_12'])\naxes[0].set_xlabel('f_28')\naxes[0].set_ylabel('f_12')\naxes[0].set_title('f_28 vs f_12')\naxes[1].scatter(train_df['f_28'],train_df['f_4'])\naxes[1].set_xlabel('f_28')\naxes[1].set_ylabel('f_4')\naxes[1].set_title('f_28 vs f_4')\naxes[2].scatter(train_df['f_23'],train_df['f_4'])\naxes[2].set_xlabel('f_23')\naxes[2].set_ylabel('f_4')\naxes[2].set_title('f_23 vs f_4')","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:22:29.979053Z","iopub.execute_input":"2023-11-14T19:22:29.979502Z","iopub.status.idle":"2023-11-14T19:22:30.893143Z","shell.execute_reply.started":"2023-11-14T19:22:29.979467Z","shell.execute_reply":"2023-11-14T19:22:30.891030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the scatter plots and correlation matrix it can be inferred that these three features exhibit strong correlation with each other. There could be redundancy in the information and noise introuduced as a result of that. Linear dimensionality reduction techniques can be evaluated to check the separation of labels.","metadata":{}},{"cell_type":"code","source":"\ntrain_df_z = train_df.apply(stats.zscore)\nX=train_df_z\ny=train_df_1['label']","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:22:30.895164Z","iopub.execute_input":"2023-11-14T19:22:30.896076Z","iopub.status.idle":"2023-11-14T19:22:30.960553Z","shell.execute_reply.started":"2023-11-14T19:22:30.896018Z","shell.execute_reply":"2023-11-14T19:22:30.959016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### PCA plot of the features","metadata":{}},{"cell_type":"code","source":"pca = PCA(n_components=4, random_state=42)\nX_pca = pca.fit(X).transform(X)\ntarget_names=train_df_1.label.unique()\nprint(X.shape)\nprint(X_pca.shape)\nprint(\"explained variance ratio (first five components): %s\"\n    % str(pca.explained_variance_ratio_))\nnp.cumsum(pca.explained_variance_ratio_)\n\nplt.figure()\n#colors = [\"navy\", \"turquoise\", \"darkorange\",\"green\",\"black\"]\nlw = 2\nfor i in target_names:\n        plt.scatter(\n        X_pca[y == i, 0], X_pca[y == i, 1], marker='.',label=i, cmap=\"Dark2\",\n        alpha=0.8, lw=lw)\nplt.legend(loc=\"best\")\nplt.title(\"PCA of London dataset\")\n#plt.ylim(-4,4)\nplt.axhline(y=0, color='black', linestyle='-')\nplt.axvline(x=0, color='black', linestyle='-')","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:22:31.733419Z","iopub.execute_input":"2023-11-14T19:22:31.733890Z","iopub.status.idle":"2023-11-14T19:22:32.240342Z","shell.execute_reply.started":"2023-11-14T19:22:31.733853Z","shell.execute_reply":"2023-11-14T19:22:32.238832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca.explained_variance_ratio_","metadata":{"execution":{"iopub.status.busy":"2023-11-14T15:59:17.535541Z","iopub.execute_input":"2023-11-14T15:59:17.536017Z","iopub.status.idle":"2023-11-14T15:59:17.545412Z","shell.execute_reply.started":"2023-11-14T15:59:17.535981Z","shell.execute_reply":"2023-11-14T15:59:17.543843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Linear models might not be a great choice.","metadata":{}},{"cell_type":"markdown","source":"###  Produce a scree-plot to look at the cumulative variance represented by the PCA eigenvectors.\n","metadata":{}},{"cell_type":"code","source":"pca = PCA(n_components=5)  ## 5 components\npca_m=pca.fit(X)\nX_pca = pca.fit(X).transform(X)\nPC_values = np.arange(pca.n_components_) + 1\nplt.plot(PC_values, pca.explained_variance_ratio_, 'o-', linewidth=2, color='blue')\nplt.title('Scree Plot for PCA Analysis on Abalone')\nplt.xlabel('Principal Component')\nplt.ylabel('Variance Explained')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-14T15:59:17.547563Z","iopub.execute_input":"2023-11-14T15:59:17.548149Z","iopub.status.idle":"2023-11-14T15:59:17.983101Z","shell.execute_reply.started":"2023-11-14T15:59:17.548105Z","shell.execute_reply":"2023-11-14T15:59:17.981801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"Variance explained by the PCA components 1 and 2 are lesser than 10% of the total variance.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"train_df_1.groupby('label').size() ## The classes are balanced","metadata":{"execution":{"iopub.status.busy":"2023-11-14T15:59:17.985035Z","iopub.execute_input":"2023-11-14T15:59:17.985430Z","iopub.status.idle":"2023-11-14T15:59:17.999407Z","shell.execute_reply.started":"2023-11-14T15:59:17.985399Z","shell.execute_reply":"2023-11-14T15:59:17.997837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The classes 0 and 1 are balanced","metadata":{}},{"cell_type":"markdown","source":"# Building models with no feature transformation","metadata":{"execution":{"iopub.status.busy":"2023-11-08T20:12:02.148859Z","iopub.execute_input":"2023-11-08T20:12:02.149262Z","iopub.status.idle":"2023-11-08T20:12:02.158263Z","shell.execute_reply.started":"2023-11-08T20:12:02.149233Z","shell.execute_reply":"2023-11-08T20:12:02.156265Z"}}},{"cell_type":"markdown","source":"### Function definitions","metadata":{}},{"cell_type":"code","source":"# Function for KNN model for range of neighbours. \ndef knn_model(n, train_x, train_y, test_x, test_y, name,p):\n    knn_acc = []\n    for i in range(1,n,5):\n        knn = neighbors.KNeighborsClassifier(n_neighbors=i, weights='distance', p=p)\n        knn.fit(train_x,train_y)\n        y_pred = knn.predict(test_x)\n        test_accuracy = accuracy_score(test_y, y_pred)\n        train_score = cross_val_score(knn, train_x, train_y, cv=5, scoring='accuracy').mean()\n        knn_acc.append((i,train_score ,test_accuracy))\n    return pd.DataFrame(knn_acc, columns=['K','Training Accuracy '+name,'Test Accuracy '+name])\n\n\n# K vs accuracy plot\ndef plot_accuracy_k(name, df):\n    plt.title('kNN: ' + name +' parameters, K vs accuracy')\n    plt.plot(df['K'].values, df['Test Accuracy '+name].values, label = 'Test accuracy '+name)\n    plt.plot(df['K'].values, df['Training Accuracy '+name].values, label = 'Training accuracy '+name)\n    plt.legend()\n    plt.legend()\n    plt.xlabel('Number of Neighbors')\n    plt.ylabel('Accuracy')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:20:04.237049Z","iopub.execute_input":"2023-11-14T19:20:04.238157Z","iopub.status.idle":"2023-11-14T19:20:04.251104Z","shell.execute_reply.started":"2023-11-14T19:20:04.238118Z","shell.execute_reply":"2023-11-14T19:20:04.249466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Splitting the training data into train and test set for validating the model","metadata":{}},{"cell_type":"code","source":"## Split the model into test and train set\nX=np.array(train_df_z) # dropping the target variable\ny=np.array(train_df_1['label']) \nrandom_state=42\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=random_state) # splitting the dataset into test and train based on 80% and 20% split","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:20:06.387110Z","iopub.execute_input":"2023-11-14T19:20:06.387547Z","iopub.status.idle":"2023-11-14T19:20:06.397904Z","shell.execute_reply.started":"2023-11-14T19:20:06.387516Z","shell.execute_reply":"2023-11-14T19:20:06.396094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:20:08.691327Z","iopub.execute_input":"2023-11-14T19:20:08.691780Z","iopub.status.idle":"2023-11-14T19:20:08.700191Z","shell.execute_reply.started":"2023-11-14T19:20:08.691744Z","shell.execute_reply":"2023-11-14T19:20:08.698735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### KNN function\n","metadata":{}},{"cell_type":"code","source":"n_classes = len(np.unique(y))\nn_neighbors=175\ndf_res =knn_model(200,  x_train, y_train, x_test, y_test, 'minkowski',2) # Storing the result after callling the function\n","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:20:37.489120Z","iopub.execute_input":"2023-11-14T19:20:37.490362Z","iopub.status.idle":"2023-11-14T19:20:39.459184Z","shell.execute_reply.started":"2023-11-14T19:20:37.490266Z","shell.execute_reply":"2023-11-14T19:20:39.457997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It can be observed from the plot that including more points beyond the number of neighbors 6 does not seem to be impacting the model performance much.","metadata":{}},{"cell_type":"code","source":"plot_accuracy_k('minkowski',df_res)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:20:42.465528Z","iopub.execute_input":"2023-11-14T19:20:42.466920Z","iopub.status.idle":"2023-11-14T19:20:42.828073Z","shell.execute_reply.started":"2023-11-14T19:20:42.466859Z","shell.execute_reply":"2023-11-14T19:20:42.826593Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_res.loc[df_res['Test Accuracy minkowski']==df_res['Test Accuracy minkowski'].max()]","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:20:20.307165Z","iopub.execute_input":"2023-11-14T19:20:20.307590Z","iopub.status.idle":"2023-11-14T19:20:20.323705Z","shell.execute_reply.started":"2023-11-14T19:20:20.307559Z","shell.execute_reply":"2023-11-14T19:20:20.322174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With 126 neighbors the performance of the KNN produces model with accuracy of 85%","metadata":{}},{"cell_type":"markdown","source":"### Multinomial Naive Bayes","metadata":{}},{"cell_type":"code","source":"# Function to perform Naive Bayes classification. Returns the test accuracy and the cross validation score\ndef naive_bayes(model, x_train, y_train, x_test, y_test):\n    model.fit(x_train, y_train)\n    cv_score = cross_val_score(model, x_train, y_train, cv = 5, scoring='accuracy')\n    y_pred = model.predict(x_test)\n    test_accuracy = accuracy_score(y_test, y_pred)\n    return cv_score.mean(), test_accuracy\n","metadata":{"execution":{"iopub.status.busy":"2023-11-14T18:53:50.143058Z","iopub.execute_input":"2023-11-14T18:53:50.144624Z","iopub.status.idle":"2023-11-14T18:53:50.154302Z","shell.execute_reply.started":"2023-11-14T18:53:50.144556Z","shell.execute_reply":"2023-11-14T18:53:50.152378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#There can be negative values which naive bayes will not accept, \n# so performing min max normalization so that the features are non negative\nscaler=MinMaxScaler()\nx_train_mm = scaler.fit_transform(x_train)\nx_test_mm = scaler.transform(x_test)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T18:53:51.847625Z","iopub.execute_input":"2023-11-14T18:53:51.848238Z","iopub.status.idle":"2023-11-14T18:53:51.859139Z","shell.execute_reply.started":"2023-11-14T18:53:51.848194Z","shell.execute_reply":"2023-11-14T18:53:51.857125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_score_cnb, test_acc_cnb = naive_bayes(ComplementNB(), x_train_mm, y_train, x_test_mm, y_test)\nprint(\"cross-val_score:\",cv_score_cnb)\nprint(\"test_acc_cnb:\",test_acc_cnb)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T18:53:52.742769Z","iopub.execute_input":"2023-11-14T18:53:52.744092Z","iopub.status.idle":"2023-11-14T18:53:52.772184Z","shell.execute_reply.started":"2023-11-14T18:53:52.744049Z","shell.execute_reply":"2023-11-14T18:53:52.770988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_score_mnb, test_acc_mnb = naive_bayes(MultinomialNB(), x_train_mm, y_train, x_test_mm, y_test)\nprint(\"cross-val_score:\",cv_score_mnb)\nprint(\"test_acc_cnb:\",test_acc_mnb)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T18:53:54.321619Z","iopub.execute_input":"2023-11-14T18:53:54.323362Z","iopub.status.idle":"2023-11-14T18:53:54.360281Z","shell.execute_reply.started":"2023-11-14T18:53:54.323286Z","shell.execute_reply":"2023-11-14T18:53:54.358749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tree based Algorithms","metadata":{}},{"cell_type":"markdown","source":"### Random Forest","metadata":{}},{"cell_type":"markdown","source":"Starting with evaluation of important features using decision trees","metadata":{}},{"cell_type":"code","source":"##Data normlisation is not required\n# Function to caculate the best set of parameters and the cross val score of that best model\ndef decsion_tree_gs(x_train, y_train,x_test):\n    params = {\n              'max_depth':list(range(2,20))\n             }\n    gs_dtc = GridSearchCV(DecisionTreeClassifier(random_state=27), params, verbose=1, cv=5, return_train_score=True, n_jobs=-1)\n\n    gs_results_dtc = gs_dtc.fit(x_train, y_train)\n    print('The best classifer is for the values - ')\n    print('One leave out Accuracy of the best model - ', gs_results_dtc.best_score_)\n    print(gs_results_dtc.best_estimator_)\n    print(gs_results_dtc.best_params_)\n    results_df = pd.DataFrame(gs_results_dtc.cv_results_['params'])\n    results_df[\"Train Accuracy\"] = gs_results_dtc.cv_results_['mean_train_score']\n    results_df[\"Valid Accuracy\"] = gs_results_dtc.cv_results_['mean_test_score']\n    return gs_results_dtc, results_df\n    \n# Function to calculate the test accuracy of the model using the best parameters ?R remove the function\ndef decision_tree_classifier(max_depth, x_train, y_train, x_test, y_test):\n    dtc = DecisionTreeClassifier(max_depth=max_depth, random_state=27)\n    dtc.fit(x_train, y_train)\n    scores = cross_val_score(dtc, x_train, y_train, cv = 5, scoring='accuracy',)\n    y_pred = dtc.predict(x_test)\n    test_accuracy = accuracy_score(y_test, y_pred)\n    return dtc, scores.mean(), test_accuracy\n\n# Plot of accuracy vs the depth for the Decision Tree Classifier\ndef plot_depth_accuracy(df,mod): \n    plt.title('Decison Tree: '+mod +' Max Depth vs Accuracy (Train and Test)')\n    plt.plot(df['max_depth'].values, df['Train Accuracy'].values, label = 'Mean Train Accuracy')\n    plt.plot(df['max_depth'].values, df['Valid Accuracy'].values, label = 'Valid Accuracy')\n    plt.legend()\n    plt.legend()\n    plt.xlabel('Max_Depth')\n    plt.ylabel('Accuracy')\n    plt.show()\n    \ndef RF_gs(x_train, y_train,x_test):\n    d_l=2\n    d_u=20\n    tree_para = {'max_depth':list(range(d_l,d_u,2)),'n_estimators':[100,120,150, 175, 200, 220, 250,300],'max_features':['sqrt','log2']}  #range(t_l,t_u,2)}\n    clf_rf =  GridSearchCV(RandomForestClassifier(),tree_para,cv=5,return_train_score=True,n_jobs=-1)\n    #gs_dtc = GridSearchCV(DecisionTreeClassifier(random_state=27), params, verbose=1, cv=5)\n    clf_rf = clf_rf.fit(x_train, y_train)\n    scores_raw_rf = cross_val_score(clf_rf, x_train, y_train, cv = 5, scoring='accuracy')\n    print('The best classifer is for the values - ')\n    print('One leave out Accuracy of the best model - ', clf_rf.best_score_)\n    print(clf_rf.best_estimator_)\n    print(clf_rf.best_params_)\n    y_pred_rf = clf_rf.predict(x_test)\n    test_accuracy_rf = accuracy_score(y_test, y_pred_rf)\n    results_df = pd.DataFrame(clf_rf.cv_results_['params'])\n    results_df[\"Train Accuracy\"] = clf_rf.cv_results_['mean_train_score']\n    results_df[\"Valid Accuracy\"] = clf_rf.cv_results_['mean_test_score']\n    return clf_rf, results_df\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:32:59.603910Z","iopub.execute_input":"2023-11-14T19:32:59.604347Z","iopub.status.idle":"2023-11-14T19:32:59.626468Z","shell.execute_reply.started":"2023-11-14T19:32:59.604306Z","shell.execute_reply":"2023-11-14T19:32:59.624872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def heatplot_depth_estimators_accuracy_valid(df ,model_n):\n        #Pivoting the dataframe for plotting heat map\n        ac_df=df.pivot(index='max_depth',columns='n_estimators',values='Valid Accuracy')\n        #Plotting the graph\n        plt.figure(figsize=(15,8))\n        sns.heatmap(data=ac_df,annot=True)\n        plt.title(\"heat plot of accuracy with \"+ model_n)\n        plt.show()\ndef heatplot_depth_estimators_accuracy_train(df,model_n):\n        #Pivoting the dataframe for plotting heat map\n        ac_df=df.pivot(index='max_depth',columns='n_estimators',values='Train Accuracy')\n        #Plotting the graph\n        plt.figure(figsize=(15,8))\n        sns.heatmap(data=ac_df,annot=True)\n        plt.title(\"heat plot of accuracy with \"+ model_n)\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:22:44.373776Z","iopub.execute_input":"2023-11-14T19:22:44.374890Z","iopub.status.idle":"2023-11-14T19:22:44.385550Z","shell.execute_reply.started":"2023-11-14T19:22:44.374815Z","shell.execute_reply":"2023-11-14T19:22:44.383985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model_dt, df_dtc = decsion_tree_gs(x_train, y_train,x_test) ## call the function and pass the parameters","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:29:09.696410Z","iopub.execute_input":"2023-11-14T19:29:09.697959Z","iopub.status.idle":"2023-11-14T19:29:11.887968Z","shell.execute_reply.started":"2023-11-14T19:29:09.697886Z","shell.execute_reply":"2023-11-14T19:29:11.886681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_depth_accuracy(df_dtc,\"\")","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:23:01.980471Z","iopub.execute_input":"2023-11-14T19:23:01.980951Z","iopub.status.idle":"2023-11-14T19:23:02.261893Z","shell.execute_reply.started":"2023-11-14T19:23:01.980915Z","shell.execute_reply":"2023-11-14T19:23:02.260236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It can be observed that the after a certain point depth of 6 the model startes overfitting because there is significant bump in the training data accuracy compared to the validation set from the cross validation excercise.","metadata":{}},{"cell_type":"code","source":"max_depth=5\ndtc, mean_error, test_accuracy=decision_tree_classifier(max_depth, x_train, y_train, x_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:23:05.486445Z","iopub.execute_input":"2023-11-14T19:23:05.487658Z","iopub.status.idle":"2023-11-14T19:23:05.606764Z","shell.execute_reply.started":"2023-11-14T19:23:05.487570Z","shell.execute_reply":"2023-11-14T19:23:05.605041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fitering the features which helps in dividing the space to separate the groups\nfeat_importance = best_model_dt.best_estimator_.tree_.compute_feature_importances(normalize=False)\n#print(\"feature importance = \" + str(feat_importance))\ndata = {'Feature':list(train_df.columns), 'feat_importance': feat_importance}  \ndf_feature_imp=pd.DataFrame(data)\ndf_feature_imp.sort_values(by='feat_importance',ascending=False).head()","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:23:07.022081Z","iopub.execute_input":"2023-11-14T19:23:07.022564Z","iopub.status.idle":"2023-11-14T19:23:07.039241Z","shell.execute_reply.started":"2023-11-14T19:23:07.022515Z","shell.execute_reply":"2023-11-14T19:23:07.037498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Gini Importance or Mean Decrease in Impurity (MDI) calculates each feature importance as the sum over the number of splits (across all tress) that include the feature, proportionally to the number of samples it splits.From the table it can inferred that the contribution of the features towards classifying the target variable is poor.","metadata":{}},{"cell_type":"code","source":"len(list(df_feature_imp[df_feature_imp['feat_importance']>0]['Feature']))","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:23:10.607269Z","iopub.execute_input":"2023-11-14T19:23:10.607779Z","iopub.status.idle":"2023-11-14T19:23:10.619566Z","shell.execute_reply.started":"2023-11-14T19:23:10.607741Z","shell.execute_reply":"2023-11-14T19:23:10.617929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Split the model into test and tr'ain set\nX=np.array(train_df[list(df_feature_imp[df_feature_imp['feat_importance']>0]['Feature'])]) # dropping the target variable\ny=np.array(train_df_1['label']) \nrandom_state=42\nx_train_rf, x_test_rf, y_train_rf, y_test_rf = train_test_split(X, y, test_size=0.2,random_state=random_state) # splitting the dataset into test and train based on 80% and 20% split","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:23:11.801195Z","iopub.execute_input":"2023-11-14T19:23:11.801639Z","iopub.status.idle":"2023-11-14T19:23:11.814780Z","shell.execute_reply.started":"2023-11-14T19:23:11.801598Z","shell.execute_reply":"2023-11-14T19:23:11.812819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model, df_rf = RF_gs(x_train_rf, y_train_rf,x_test_rf) ## call the function and pass the parameters (25 minutes run time)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:33:03.465266Z","iopub.execute_input":"2023-11-14T19:33:03.465723Z","iopub.status.idle":"2023-11-14T19:49:45.499576Z","shell.execute_reply.started":"2023-11-14T19:33:03.465687Z","shell.execute_reply":"2023-11-14T19:49:45.497918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_rf.abshead()","metadata":{"execution":{"iopub.status.busy":"2023-11-14T17:02:25.776251Z","iopub.execute_input":"2023-11-14T17:02:25.776930Z","iopub.status.idle":"2023-11-14T17:02:25.793162Z","shell.execute_reply.started":"2023-11-14T17:02:25.776891Z","shell.execute_reply":"2023-11-14T17:02:25.791236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The heatmap is plotted for both the training and validation accuracy based on K fold cross validatpion. ","metadata":{}},{"cell_type":"code","source":"#model_n=\"Random forest Raw Dataset Training\"\n#heatplot_depth_estimators_accuracy_train(df_rf,model_n)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-14T17:01:57.348298Z","iopub.execute_input":"2023-11-14T17:01:57.348815Z","iopub.status.idle":"2023-11-14T17:01:58.011412Z","shell.execute_reply.started":"2023-11-14T17:01:57.348779Z","shell.execute_reply":"2023-11-14T17:01:58.009554Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model_n=\"Random forest Raw Dataset Validation\"\n#heatplot_depth_estimators_accuracy_valid(df_rf,model_n)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-14T17:02:59.552167Z","iopub.execute_input":"2023-11-14T17:02:59.552633Z","iopub.status.idle":"2023-11-14T17:03:00.169572Z","shell.execute_reply.started":"2023-11-14T17:02:59.552597Z","shell.execute_reply":"2023-11-14T17:03:00.167959Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Gradient Boosting Classifier","metadata":{}},{"cell_type":"code","source":"def gbt(x_train, y_train,x_test):\n    tree_para = {'n_estimators': [150,200,220,300,350,400,450,500,550]}  #[20,50,70,90,100]}  #range(t_l,t_u,2)}#20,50,70,90,100,120,\n    clf =  GridSearchCV(GradientBoostingClassifier(learning_rate=0.01),tree_para,cv=5,return_train_score=True,n_jobs=-1)\n    clf = clf.fit(x_train, y_train)\n    scores_raw_rf = cross_val_score(clf, x_train, y_train, cv = 5, scoring='accuracy')\n    print('The best classifer is for the values - ')\n    print('One leave out Accuracy of the best model - ', clf.best_score_)\n    print(clf.best_estimator_)\n    print(clf.best_params_)\n    y_pred_rf = clf.predict(x_test)\n    test_accuracy_rf = accuracy_score(y_test, y_pred_rf)\n    results_df = pd.DataFrame(clf.cv_results_['params'])\n    results_df[\"Train Accuracy\"] = clf.cv_results_['mean_train_score']\n    results_df[\"Valid Accuracy\"] = clf.cv_results_['mean_test_score']\n    return clf, results_df\n\ndef plot_depth_accuracy_gb(df,mod): \n    plt.title('Gradient Boosted Tree: '+mod +' Estimators vs Accuracy (Train and Test)')\n    plt.plot(df['n_estimators'].values, df['Train Accuracy'].values, label = 'Mean Train Accuracy')\n    plt.plot(df['n_estimators'].values, df['Valid Accuracy'].values, label = 'Valid Accuracy')\n    plt.legend()\n    plt.legend()\n    plt.xlabel('n_estimators')\n    plt.ylabel('Accuracy')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-14T18:54:51.962694Z","iopub.execute_input":"2023-11-14T18:54:51.964248Z","iopub.status.idle":"2023-11-14T18:54:51.981782Z","shell.execute_reply.started":"2023-11-14T18:54:51.964169Z","shell.execute_reply":"2023-11-14T18:54:51.979933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Passing the training array with the selcted features\n#best_model_gbt, df_gbt_raw = gbt(x_train_rf, y_train_rf,x_test_rf) #Assessed with the tress  20,50,70,90,100,150,200,220","metadata":{"execution":{"iopub.status.busy":"2023-11-14T17:56:34.087465Z","iopub.execute_input":"2023-11-14T17:56:34.087910Z","iopub.status.idle":"2023-11-14T17:57:36.443824Z","shell.execute_reply.started":"2023-11-14T17:56:34.087877Z","shell.execute_reply":"2023-11-14T17:57:36.442591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Passing the training array with the selcted features\nbest_model_gbt, df_gbt_raw = gbt(x_train_rf, y_train_rf,x_test_rf) ","metadata":{"execution":{"iopub.status.busy":"2023-11-14T18:55:02.385375Z","iopub.execute_input":"2023-11-14T18:55:02.385899Z","iopub.status.idle":"2023-11-14T18:57:39.848966Z","shell.execute_reply.started":"2023-11-14T18:55:02.385862Z","shell.execute_reply":"2023-11-14T18:57:39.847223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_depth_accuracy_gb(df_gbt_raw,\"Gradient Boosted Trees\")","metadata":{"execution":{"iopub.status.busy":"2023-11-14T18:57:39.851650Z","iopub.execute_input":"2023-11-14T18:57:39.852055Z","iopub.status.idle":"2023-11-14T18:57:40.200290Z","shell.execute_reply.started":"2023-11-14T18:57:39.852021Z","shell.execute_reply":"2023-11-14T18:57:40.199133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After testing the performance of each model with the cross validation technique it can be concluded that the validation accuracy reported is best for  Random Forest and XGBoost models.","metadata":{}},{"cell_type":"markdown","source":"The best classifer is for the values - \n\nOne leave out Accuracy of the best model -  0.89\n\nRandomForestClassifier(max_depth=18)\n\n{'max_depth': 18, 'n_estimators': 100}","metadata":{}},{"cell_type":"code","source":"##Values are passed based on the RF evaluation\nrf_f=RandomForestClassifier(max_depth=18,n_estimators=100,random_state=27)\nrf_f.fit(x_train_rf,y_train_rf)\nscore=cross_val_score(rf_f,x_train_rf,y_train_rf,cv=5,scoring='accuracy')\ny_pred=rf_f.predict(x_test_rf)\ntest_accuracy=accuracy_score(y_test_rf,y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:27:18.627731Z","iopub.execute_input":"2023-11-14T19:27:18.629233Z","iopub.status.idle":"2023-11-14T19:27:20.996022Z","shell.execute_reply.started":"2023-11-14T19:27:18.629176Z","shell.execute_reply":"2023-11-14T19:27:20.994621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"test_accuracy:\",test_accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:27:31.698462Z","iopub.execute_input":"2023-11-14T19:27:31.699210Z","iopub.status.idle":"2023-11-14T19:27:31.708735Z","shell.execute_reply.started":"2023-11-14T19:27:31.699148Z","shell.execute_reply":"2023-11-14T19:27:31.707070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Testing results of the tuned RF\n'max_depth': 18, 'max_features': 'sqrt', 'n_estimators': 175","metadata":{}},{"cell_type":"code","source":"##Values are passed based on the RF evaluation\nrf_f=RandomForestClassifier(max_depth=18,n_estimators=150,random_state=27,criterion='entropy')\nrf_f.fit(x_train_rf,y_train_rf)\nscore=cross_val_score(rf_f,x_train_rf,y_train_rf,cv=5,scoring='accuracy')\ny_pred=rf_f.predict(x_test_rf)\ntest_accuracy=accuracy_score(y_test_rf,y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T20:04:27.791183Z","iopub.execute_input":"2023-11-14T20:04:27.791636Z","iopub.status.idle":"2023-11-14T20:04:31.742625Z","shell.execute_reply.started":"2023-11-14T20:04:27.791602Z","shell.execute_reply":"2023-11-14T20:04:31.741285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"test_accuracy:\",test_accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T20:04:31.744685Z","iopub.execute_input":"2023-11-14T20:04:31.745037Z","iopub.status.idle":"2023-11-14T20:04:31.751710Z","shell.execute_reply.started":"2023-11-14T20:04:31.745006Z","shell.execute_reply":"2023-11-14T20:04:31.750234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Extracting features after GMM fit ","metadata":{}},{"cell_type":"code","source":"grid_space={'max_depth':[3,5,10,None],\n              'n_estimators':[10,100,200],\n              'min_samples_leaf':[1,2,3],\n              'min_samples_split':[1,2,3]\n           }","metadata":{"execution":{"iopub.status.busy":"2023-11-14T20:41:46.356852Z","iopub.execute_input":"2023-11-14T20:41:46.357412Z","iopub.status.idle":"2023-11-14T20:41:46.365333Z","shell.execute_reply.started":"2023-11-14T20:41:46.357368Z","shell.execute_reply":"2023-11-14T20:41:46.363371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf=RandomForestClassifier()\ngrid_search_rf = GridSearchCV(rf, param_grid=grid_space, verbose=3,scoring='accuracy',cv=10).fit(x_train,y_train)\nprint('best estimator RandomForest:',grid_search_rf.best_estimator_,'Best Score', grid_search_rf.best_estimator_.score(x_train,y_train))\nrf_best = grid_search_rf.best_estimator_","metadata":{"execution":{"iopub.status.busy":"2023-11-14T20:41:47.918006Z","iopub.execute_input":"2023-11-14T20:41:47.918457Z","iopub.status.idle":"2023-11-14T20:42:32.516637Z","shell.execute_reply.started":"2023-11-14T20:41:47.918423Z","shell.execute_reply":"2023-11-14T20:42:32.514253Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Values are passed based on the RF evaluation\nrf_f=RandomForestClassifier(max_depth=18,n_estimators=20,random_state=27,criterion='entropy')\nrf_f.fit(x_train,y_train)\nscore=cross_val_score(rf_f,x_train,y_train,cv=5,scoring='accuracy')\ny_pred=rf_f.predict(x_test)\ntest_accuracy=accuracy_score(y_test,y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T20:32:25.623761Z","iopub.execute_input":"2023-11-14T20:32:25.624214Z","iopub.status.idle":"2023-11-14T20:32:26.037251Z","shell.execute_reply.started":"2023-11-14T20:32:25.624180Z","shell.execute_reply":"2023-11-14T20:32:26.036038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T20:32:27.025861Z","iopub.execute_input":"2023-11-14T20:32:27.026279Z","iopub.status.idle":"2023-11-14T20:32:27.034437Z","shell.execute_reply.started":"2023-11-14T20:32:27.026250Z","shell.execute_reply":"2023-11-14T20:32:27.032917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ext=np.array(test_df[list(df_feature_imp[df_feature_imp['feat_importance']>0]['Feature'])])\ntest_ext.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:03:07.349502Z","iopub.execute_input":"2023-11-14T19:03:07.350030Z","iopub.status.idle":"2023-11-14T19:03:07.365030Z","shell.execute_reply.started":"2023-11-14T19:03:07.349975Z","shell.execute_reply":"2023-11-14T19:03:07.363129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list(df_feature_imp[df_feature_imp['feat_importance']>0]['Feature'])\nlist(df_feature_imp[df_feature_imp['feat_importance']>0]['Feature'])","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:01:50.132491Z","iopub.execute_input":"2023-11-14T19:01:50.133104Z","iopub.status.idle":"2023-11-14T19:01:50.148019Z","shell.execute_reply.started":"2023-11-14T19:01:50.133057Z","shell.execute_reply":"2023-11-14T19:01:50.145975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_test_label=rf_f.predict(test_ext)\npred_test_label","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:03:12.003231Z","iopub.execute_input":"2023-11-14T19:03:12.004139Z","iopub.status.idle":"2023-11-14T19:03:12.133127Z","shell.execute_reply.started":"2023-11-14T19:03:12.004079Z","shell.execute_reply":"2023-11-14T19:03:12.131363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_test_label[pred_test_label>0].shape","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:04:35.652865Z","iopub.execute_input":"2023-11-14T19:04:35.654428Z","iopub.status.idle":"2023-11-14T19:04:35.662975Z","shell.execute_reply.started":"2023-11-14T19:04:35.654369Z","shell.execute_reply":"2023-11-14T19:04:35.661571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Id=[x+1 for x in test_df.index.tolist()]\nId","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:11:38.910807Z","iopub.execute_input":"2023-11-14T19:11:38.911335Z","iopub.status.idle":"2023-11-14T19:11:38.947868Z","shell.execute_reply.started":"2023-11-14T19:11:38.911299Z","shell.execute_reply":"2023-11-14T19:11:38.945883Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_submission = pd.DataFrame({'Id':Id,'Solution': pred_test_label})\n# Submitting the predictions\nmy_submission.to_csv('submission.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-14T19:12:05.292282Z","iopub.execute_input":"2023-11-14T19:12:05.292870Z","iopub.status.idle":"2023-11-14T19:12:05.307252Z","shell.execute_reply.started":"2023-11-14T19:12:05.292828Z","shell.execute_reply":"2023-11-14T19:12:05.305760Z"},"trusted":true},"execution_count":null,"outputs":[]}]}